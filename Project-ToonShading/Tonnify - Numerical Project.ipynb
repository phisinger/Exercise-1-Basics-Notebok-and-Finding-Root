{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toonify (Cel-Shading)\n",
    "The goal of the algorithm is to create a cel shaded image out of a normal image or well shaded object.\\\n",
    "**=> Check the last cell for a easy-to-use function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the picture\n",
    "(Please remember to run all the cells again after choosing a new image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# select the picture\n",
    "#img = cv2.imread(\"teapot_gray.png\")\n",
    "#img = cv2.imread(\"car.jpeg\")\n",
    "#img = cv2.imread(\"face.jpg\")\n",
    "#img = cv2.imread(\"face2.jfif\")\n",
    "#img = cv2.imread(\"dolphin.jpg\")\n",
    "#img = cv2.imread(\"teapot_white.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Edges\n",
    "First, we convert the picture to levels of gray to enable a better detection of the edges without any disruptive colors.\\\n",
    "\\\n",
    "Second, we use the **medianBlur** algorithm to blur any unwanted noise which could be interpreted as edges. MedianBlur makes sure to protect edges but blur surfaces and everything else. It uses a 13x13 pixel matrix (neighborhood) and replace each pixel with the median of its neighboring pixels. The median filter uses BORDER_REPLICATE internally to cope with border pixels.\\\n",
    "\\\n",
    "Third, we use **Canny** algorithm to finally detect edges. Even though this edge detection algorithm uses a gaussian filter to reduce noise, median filter before results in clearer edges. In stage two, Canny derives horizontal and vertical gradients by using Sobel kernel to find both edge gradient and direction for each pixel.\\\n",
    "In the end Canny uses thresholding to decide which pixels/lines are really edges and which are not: If a pixel's value is below the minV it is definitely not an edge, and if its value is above maxV it definitely is an edge. For every pixel between the two thresholds, Canny checks if it is connected to a pixel that's definitely part of an edge. If that is the case, it is also considered to be part of the edge.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_edges(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.medianBlur(gray, 13)\n",
    "    # Edge detection with canny\n",
    "    edges = cv2.Canny(gray, 50, 80)\n",
    "    # an invertation is necessairy to have black edges and not white ones\n",
    "    edges = (255-edges)\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Colors\n",
    "Now, we simplify colors in the image to create the blocky, minimalized look that creates the \"cartoon\"-appearance we want to achieve.\n",
    "\n",
    "First, the image needs to be resized, as the following algorithm is very expensive in regards to computation time etc.\\\n",
    "After resizing, we start by blurring all the colors using an algorithm similar to a gaussian algorithm; each pixel is assigned some weighted sum of its immediate neigbours. However, we wish to blur the image multiple times, and by reusing this algorithm we're bound to lose the important sharper edges in the image.\\\n",
    "To keep this from happening, the weighing of the neighbouring pixels depends on how close their value is to that of the inspected pixel. The bigger the difference in value, the smaller the weight.\n",
    "This preserves high-contrast edges and creates clear, one-coloured surfaces in the end.\n",
    "\n",
    "After doing this, the picture is resized using linear interpolation. \\\n",
    "To get rid of any small errors caused by this process, a median filter is applied to the picture afterwards.\n",
    "\n",
    "The last step in simplifying the colors is quantizing. The goal of this step is to reduce the total amount of colours in the picture. To do this, the following formula is applied to all color channels: \n",
    "\n",
    "$$p_{new} = \\left\\lfloor \\frac{p}{a}\\right\\rfloor \\times a$$\n",
    "\n",
    "(p is the pixel value and a is the factor by which the number of colours is reduced)\n",
    "\n",
    "With this, the recoloring-process is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coloring(img):\n",
    "    color = img.copy()\n",
    "    # smooth the colors within one color area\n",
    "    for _ in range(2):\n",
    "        color = cv2.medianBlur(color, 7)\n",
    "\n",
    "    # quantise colors:\n",
    "    Z = color.reshape((-1,3))\n",
    "\n",
    "    # convert to np.float32\n",
    "    Z = np.float32(Z)\n",
    "\n",
    "    # define criteria, number of clusters(K) and apply kmeans()\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "    K = 4\n",
    "    ret,label,center=cv2.kmeans(Z,K,None,criteria,10,cv2.KMEANS_RANDOM_CENTERS)\n",
    "\n",
    "    # Now convert back into uint8, and make original image\n",
    "    center = np.uint8(center)\n",
    "    res = center[label.flatten()]\n",
    "    color_res = res.reshape((color.shape))\n",
    "    return color_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) All together\n",
    "Finally, we combine the results of step 1) and step 2). We use the bitwise_and to put the color part and the edge part into one picture. The black edges are used as a mask in the AND operations between two instances of the same color picture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-2a66fbf63e62>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtoonify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def toonify(image):\n",
    "    img = cv2.imread(image)\n",
    "    edges = detect_edges(img)\n",
    "    colors = coloring(img)\n",
    "    cartoon = cv2.bitwise_and(colors, colors, mask=edges)\n",
    "    return img,cartoon\n",
    "\n",
    "def show(img, cartoon):\n",
    "    cv2.imshow(\"Image\", img)\n",
    "    cv2.imshow(\"Cartoon\", cartoon)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "\n",
    "images = [\"teapot_gray.png\",\"car.jpeg\",\"face.jpg\",\"face2.jfif\",\"dolphin.jpg\",\"teapot_white.png\"]\n",
    "for picture in images:\n",
    "    img, result = toonify(picture)\n",
    "    fig, (ax1, ax2) = plt.subplots(1,2, figsize=(17,17))\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title(\"Original Image\"), \n",
    "    ax1.set_xticks([]), ax1.set_yticks([])\n",
    "    ax2.imshow(result)\n",
    "    ax2.set_title(\"Cartoon Image\"), \n",
    "    ax2.set_xticks([]), ax2.set_yticks([])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
